import os
import gc
import argparse
from pathlib import Path
from tqdm import tqdm
from faster_whisper import WhisperModel
import torch
import shutil
import sys
import traceback
import subprocess
import json

# =======================
# åƒæ•¸è¨­å®š
# =======================
parser = argparse.ArgumentParser()
parser.add_argument("--input_dir", required=True, help="æš«å­˜éŸ³æª”ç›®éŒ„ (temp_audio)")
parser.add_argument("--base_name", required=True, help="åŸå½±ç‰‡æª”åï¼ˆç¨‹å¼æœƒå– stemï¼‰")
parser.add_argument("--generate_txt", type=str, default="true", help="æ˜¯å¦è¼¸å‡º TXT")
parser.add_argument("--generate_srt", type=str, default="true", help="æ˜¯å¦è¼¸å‡º SRT")
parser.add_argument("--cleanup_temp", type=str, default="true", help="æ˜¯å¦åˆªé™¤æš«å­˜éŸ³æª”")
parser.add_argument("--language", type=str, default="zh", help="èªè¨€ä»£ç¢¼ï¼Œä¾‹å¦‚ zhã€en")
args = parser.parse_args()

TEMP_DIR = Path(args.input_dir)
TRANSCRIPTS_DIR = Path("transcripts")
TRANSCRIPTS_DIR.mkdir(parents=True, exist_ok=True)
BASE_NAME = Path(args.base_name).stem

MODEL_PATH = Path("/home/jay/whisper/models/medium")  # æ¨¡å‹è·¯å¾‘
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def str2bool(s):
    return str(s).lower() in ("1", "true", "yes", "y")

generate_txt = str2bool(args.generate_txt)
generate_srt = str2bool(args.generate_srt)
cleanup_temp = str2bool(args.cleanup_temp)
language = args.language

# VAD è¨­å®š
USE_VAD = True
VAD_PARAMS = dict(min_silence_duration_ms=100)

# =======================
# å·¥å…·å‡½æ•¸
# =======================
def format_time(t: float) -> str:
    """å°‡ç§’æ•¸è½‰ç‚º SRT æ™‚é–“æ ¼å¼ HH:MM:SS,mmm"""
    h = int(t // 3600)
    m = int((t % 3600) // 60)
    s = int(t % 60)
    ms = int(round((t - int(t)) * 1000))
    if ms >= 1000:
        s += 1
        ms -= 1000
    if s >= 60:
        m += 1
        s -= 60
    if m >= 60:
        h += 1
        m -= 60
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

def transcribe_one(model, audio_path):
    """ä½¿ç”¨ Whisper æ¨¡å‹è½‰å¯«å–®å€‹éŸ³æª”ï¼Œå›å‚³ segments èˆ‡ info"""
    if USE_VAD:
        try:
            segments, info = model.transcribe(
                str(audio_path),
                beam_size=5,
                language=language,
                vad_filter=True,
                vad_parameters=VAD_PARAMS
            )
        except TypeError:
            # æŸäº›ç‰ˆæœ¬ä¸æ”¯æ´ vad_parameters
            segments, info = model.transcribe(
                str(audio_path),
                beam_size=5,
                language=language,
                vad_filter=True
            )
    else:
        segments, info = model.transcribe(
            str(audio_path),
            beam_size=5,
            language=language,
            vad_filter=False
        )
    return list(segments), info

def calculate_duration(segments, info):
    """è¨ˆç®—éŸ³æª”ç¸½æ™‚é•·ï¼Œå„ªå…ˆ info.duration"""
    total_secs = None
    if getattr(info, "duration", None):
        try:
            total_secs = float(info.duration)
        except:
            total_secs = None
    if total_secs is None:
        total_secs = sum(max(0.0, s.end - s.start) for s in segments)
    return total_secs or 0.0

def write_segments(segments, cumulative_time, final_txt_f, final_srt_f, segment_counter):
    """å°‡ segments å¯«å…¥ TXT èˆ‡ SRTï¼Œè¿”å›æ›´æ–°å¾Œçš„ segment_counter"""
    for s in segments:
        start_adj = s.start + cumulative_time
        end_adj = s.end + cumulative_time

        if final_txt_f:
            final_txt_f.write(s.text.strip() + "\n")

        if final_srt_f:
            final_srt_f.write(f"{segment_counter}\n")
            final_srt_f.write(f"{format_time(start_adj)} --> {format_time(end_adj)}\n")
            final_srt_f.write(s.text.strip() + "\n\n")
            segment_counter += 1
    return segment_counter

def get_ffprobe_duration(audio_path):
    """ä½¿ç”¨ ffprobe å¿«é€Ÿç²å–éŸ³æª”æ™‚é•·ï¼Œä¸è·‘æ¨¡å‹"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-select_streams", "a:0",
             "-show_entries", "stream=duration", "-of", "json",
             str(audio_path)],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        data = json.loads(result.stdout)
        duration = float(data["streams"][0]["duration"])
        return duration
    except Exception:
        return 0.0

# =======================
# æª¢æŸ¥è³‡æ–™
# =======================
if not TEMP_DIR.exists():
    print(f"æ‰¾ä¸åˆ°æš«å­˜ç›®éŒ„ {TEMP_DIR}", file=sys.stderr)
    sys.exit(1)

audio_files = sorted(TEMP_DIR.glob("part*.mp3"))
if not audio_files:
    print("æ²’æœ‰æ‰¾åˆ° part*.mp3 æª”æ¡ˆ", file=sys.stderr)
    sys.exit(1)

# =======================
# è¼‰å…¥æ¨¡å‹
# =======================
print(f"é–‹å§‹è¼‰å…¥ Whisper æ¨¡å‹: {MODEL_PATH} on {DEVICE} ...")
model = WhisperModel(str(MODEL_PATH), device=DEVICE, compute_type="float16")
if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")

# =======================
# é æƒæç¸½é•·åº¦ï¼ˆffprobeï¼‰
# =======================
print("æƒææ‰€æœ‰åˆ†æ®µé•·åº¦ï¼ˆä½¿ç”¨ ffprobeï¼Œä¸æœƒè·‘æ¨¡å‹ï¼‰...")
durations = [get_ffprobe_duration(p) for p in audio_files]
total_video_secs = sum(durations)
print(f"ç™¼ç¾ {len(audio_files)} å€‹åˆ†æ®µï¼Œç¸½é•·åº¦ {total_video_secs:.1f} ç§’")

# ä½¿ç”¨ç°¡å–®ç¸½é€²åº¦æ¢ï¼ˆæ¯å€‹éŸ³æª”å®Œæˆå°±æ›´æ–°ï¼‰
global_pbar = tqdm(total=len(audio_files), unit="file", desc="å½±ç‰‡ç¸½é€²åº¦", ncols=100)

# =======================
# æº–å‚™è¼¸å‡º
# =======================
final_txt_f = open(TRANSCRIPTS_DIR / f"{BASE_NAME}.txt", "w", encoding="utf-8") if generate_txt else None
final_srt_f = open(TRANSCRIPTS_DIR / f"{BASE_NAME}.srt", "w", encoding="utf-8") if generate_srt else None

segment_counter = 1
cumulative_time = 0.0  # ç”¨æ–¼ SRT ç´¯ç©æ™‚é–“

# =======================
# æ­£å¼è½‰å¯«
# =======================
try:
    for idx, audio_path in enumerate(audio_files, start=1):
        print(f"\nğŸ¬ è™•ç†æ®µè½ ({idx}/{len(audio_files)}): {audio_path.name}")
        try:
            segments, info = transcribe_one(model, audio_path)
        except Exception as e:
            print(f"âŒ è½‰å¯«å¤±æ•—: {audio_path.name}, {e}", file=sys.stderr)
            traceback.print_exc()
            continue

        total_secs = calculate_duration(segments, info)

        # å¯«å…¥ TXT / SRT
        segment_counter = write_segments(
            segments,
            cumulative_time,
            final_txt_f,
            final_srt_f,
            segment_counter
        )

        # æ›´æ–°ç´¯ç©æ™‚é–“
        cumulative_time += total_secs

        # æ›´æ–°ç¸½é€²åº¦æ¢ï¼šæ¯å®Œæˆä¸€å€‹ mp3 å°±æ›´æ–°
        global_pbar.update(1)

        # VRAM æ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

finally:
    if final_txt_f:
        final_txt_f.close()
    if final_srt_f:
        final_srt_f.close()
    global_pbar.close()

# =======================
# åˆªé™¤æš«å­˜éŸ³æª”ï¼ˆå¯é¸ï¼‰
# =======================
if cleanup_temp:
    shutil.rmtree(TEMP_DIR, ignore_errors=True)

print("\nâœ… è½‰å¯«å®Œæˆ")
